{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d628932-9346-44e1-8cf1-8c1a059ca023",
   "metadata": {},
   "source": [
    "# データ分割\n",
    "\n",
    "- サイトからデータをダウンロードしたディレクトリをDARA_DIR \n",
    "データ分割し，trian,valデータをコピーするディレクトリをOUTPUT_DIR　とする\n",
    "\n",
    "- 分割比率は訓練：評価 = 8:2としている\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852806c8-898e-4ac1-8bb6-83f2c391b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像の分割とコピーが完了しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# 元のデータディレクトリと保存先ディレクトリ\n",
    "DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/train/train\"\n",
    "OUTPUT_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/split_data2\"\n",
    "\n",
    "# 分割比率\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# クラスのディレクトリを取得（not-hold, hold）\n",
    "class_dirs = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "\n",
    "# 保存先ディレクトリの作成\n",
    "for split in ['train', 'val']:\n",
    "    for class_dir in class_dirs:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, split, class_dir), exist_ok=True)\n",
    "\n",
    "# 各クラスごとに画像をランダムに分割し、対応するフォルダにコピー\n",
    "for class_dir in class_dirs:\n",
    "    image_paths = glob(os.path.join(DATA_DIR, class_dir, '*.jpg'))\n",
    "    random.shuffle(image_paths)\n",
    "\n",
    "    # データを分割\n",
    "    train_idx = int(len(image_paths) * train_ratio)\n",
    "    train_images = image_paths[:train_idx]\n",
    "    val_images = image_paths[train_idx:]\n",
    "\n",
    "    # 各セットに画像をコピー\n",
    "    for image in train_images:\n",
    "        shutil.copy(image, os.path.join(OUTPUT_DIR, 'train', class_dir))\n",
    "    for image in val_images:\n",
    "        shutil.copy(image, os.path.join(OUTPUT_DIR, 'val', class_dir))\n",
    "\n",
    "print(\"画像の分割とコピーが完了しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce6683-8f83-4bf5-8743-8c2a794a6963",
   "metadata": {},
   "source": [
    "# データオーギュメンテーション\n",
    "- RandomBrightnessContrast(ランダムに明るさ・コントラストを変更)\n",
    "- RandomGamma(ランダムにガンマ変換をかける)\n",
    "- ShiftScaleRotate(ランダムにアフィン変換をかける．平行移動，拡大縮小)\n",
    "\n",
    "- これらのデータオーギュメンテーションの発生率を設定して，各画像に上記3つのデータオーギュメンテーションを施す．これを各画像に対して３回行うことにより，訓練データを４倍にする．\n",
    "- 今回のデータオーギュメンテーションでは，反転，回転などの加工は行わなかった．理由→舞踊は形式通りの動きしかしないことを考慮すると，ダンスの形が変わるような回転，反転の加工は不要だと判断した．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dda47d-ca63-4843-91fe-b0eeac50491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as albu\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 元のデータディレクトリと保存先ディレクトリ\n",
    "DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/split_data\"\n",
    "AUGMENTED_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/augmented_data2\"\n",
    "CLASS_NAMES = [\"not-hold\", \"hold\"]\n",
    "\n",
    "# オーギュメンテーションの設定\n",
    "augmentation = albu.Compose([\n",
    "    albu.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=0.3),\n",
    "    albu.RandomGamma(gamma_limit=(70, 130), p=0.3),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=0, p=0.5)  # 回転角度を0に設定\n",
    "])\n",
    "\n",
    "# 各クラスごとに増強データを生成して保存\n",
    "num_augmentations = 3  # 1つの画像につき生成するバリエーションの数\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_dir = os.path.join(DATA_DIR, \"train\", class_name)\n",
    "    save_dir = os.path.join(AUGMENTED_DATA_DIR, class_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    image_paths = glob.glob(f\"{class_dir}/*.jpg\")\n",
    "    for image_path in tqdm(image_paths, desc=f\"Processing {class_name} images\"):\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "        base_name = os.path.basename(image_path).split('.')[0]\n",
    "\n",
    "        # 指定した回数分オーギュメンテーションを適用し、保存\n",
    "        for i in range(num_augmentations):\n",
    "            augmented = augmentation(image=image)['image']\n",
    "            augmented_image = Image.fromarray(augmented)\n",
    "            augmented_image.save(os.path.join(save_dir, f\"{base_name}_aug_{i}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb58676-1af2-4776-9e06-db9f52b6e889",
   "metadata": {},
   "source": [
    "# ResNet学習（ファインチューニング）\n",
    "-\n",
    "- 特徴量抽出部分の重みはImage-Netで学習済みのものを使用．その後の全結合層は重みを初期化して学習する．\n",
    "- すべての重みを学習し直すため，処理がすごく重い．．．（全結合層だけ学習したほうが良いかも）．一応，今回のコンペでは上位の精度(F1-score)が0.999付近となっており，非常に高い精度が求められていた．また，訓練データとテストデータで同じ部屋，扇子，人物のデータが使用されているため，過学習気味の方が高い精度が出るのではと思った．そこで，全重みを学習して，本データに特化させたかった．\n",
    "\n",
    "- 損失関数：CrossEntropyLoss\n",
    "- optimizer：SGD\n",
    "\n",
    "- 以降のカリキュラム学習・アンサンブルのために，各サンプルに対して['file_name', 'True_Label', 'Predicted_Label', 'Confidence']をcsv出力させる\n",
    "- ここでConfidence値とは最終出力層(Softmax)におけるもっとも数値の高いノードの値である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0c7471-f567-45b7-a58d-260beb64ff06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet50\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# シード値の設定\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# データの格納先ディレクトリとクラス名\n",
    "ORIGINAL_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/split_data\"\n",
    "AUGMENTED_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/augmented_data2\"\n",
    "CLASS_NAMES = [\"not-hold\", \"hold\"]\n",
    "OUTPUT_CSV = \"predictions_with_confidences_ResNet_aug.csv\"\n",
    "MODEL_PATH = \"best_model_ResNet_aug.pth\"\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "# カスタムデータセットクラス（元データと増強データを組み合わせる）\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, original_data_dir, augmented_data_dir, split, class_names=CLASS_NAMES, transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform if transform else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        # 元のデータを追加\n",
    "        for label, class_name in enumerate(class_names):\n",
    "            original_class_dir = os.path.join(original_data_dir, split, class_name)\n",
    "            original_image_paths = glob.glob(f\"{original_class_dir}/*.jpg\")\n",
    "            self.images.extend(original_image_paths)\n",
    "            self.labels.extend([label] * len(original_image_paths))\n",
    "\n",
    "            # 増強データを追加\n",
    "            augmented_class_dir = os.path.join(augmented_data_dir, class_name)\n",
    "            augmented_image_paths = glob.glob(f\"{augmented_class_dir}/*.jpg\")\n",
    "            self.images.extend(augmented_image_paths)\n",
    "            self.labels.extend([label] * len(augmented_image_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        file_name = os.path.basename(self.images[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, file_name\n",
    "\n",
    "\n",
    "# データローダーの準備\n",
    "def get_dataloaders(batch_size=8):\n",
    "    train_dataset = MyDataset(ORIGINAL_DATA_DIR, AUGMENTED_DATA_DIR, split='train')\n",
    "    val_dataset = MyDataset(ORIGINAL_DATA_DIR, AUGMENTED_DATA_DIR, split='val')  # 増強データは含めない\n",
    "    test_dataset = MyDataset(ORIGINAL_DATA_DIR, AUGMENTED_DATA_DIR, split='test')  # 増強データは含めない\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "    # 訓練関数\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# モデルの訓練、評価、保存を行う関数\n",
    "def train_model():\n",
    "    train_loader, val_loader, test_loader = get_dataloaders()\n",
    "\n",
    "    # モデルの設定\n",
    "    model = resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, len(CLASS_NAMES))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # 最小検証損失とそれに対応するモデルパラメータを保存\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "\n",
    "\n",
    "    scaler = GradScaler()  # スケーラの設定\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target, _) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():  # 混合精度モードの適用\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch} | Batch {batch_idx} | Loss {running_loss / (batch_idx + 1):.6f}')\n",
    "\n",
    "    # 評価関数\n",
    "    def evaluate(loader):\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_file_names = []\n",
    "        total_loss = 0.0\n",
    "        confidences = []\n",
    "        with torch.no_grad():\n",
    "            for data, target, file_name in loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                total_loss += loss.item()\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                conf, preds = torch.max(probs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(target.cpu().numpy())\n",
    "                all_file_names.extend(file_name)\n",
    "                confidences.extend(conf.cpu().numpy())\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        return all_labels, all_preds, all_file_names, confidences, avg_loss\n",
    "\n",
    "    # 訓練プロセスの実行\n",
    "    num_epochs = 8\n",
    "    for epoch in range(num_epochs):\n",
    "        train(epoch)\n",
    "        _, _, _, _, val_loss = evaluate(val_loader)\n",
    "        print(f'Epoch {epoch} Validation Loss: {val_loss:.6f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # 最適なモデルの保存\n",
    "    torch.save(best_model_state, MODEL_PATH)\n",
    "    print(f\"最適なモデルが保存されました (Validation Loss: {best_val_loss:.6f})\")\n",
    "\n",
    "    # テストデータでの評価とCSV出力\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    all_labels, all_predictions, all_file_names, confidences, _ = evaluate(test_loader)\n",
    "\n",
    "    # 各クラスごとの精度\n",
    "    num_classes = len(CLASS_NAMES)\n",
    "    for i in range(num_classes):\n",
    "        class_labels = np.array(all_labels) == i\n",
    "        class_predictions = np.array(all_predictions) == i\n",
    "        precision = precision_score(class_labels, class_predictions)\n",
    "        recall = recall_score(class_labels, class_predictions)\n",
    "        f1 = f1_score(class_labels, class_predictions)\n",
    "        print(f'Class {i} - Precision: {precision:.6f}, Recall: {recall:.6f}, F1 Score: {f1:.6f}')\n",
    "\n",
    "    # CSVファイルにファイル名、真のラベル、予測ラベル、確信度を保存\n",
    "    with open(OUTPUT_CSV, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['file_name', 'True_Label', 'Predicted_Label', 'Confidence'])\n",
    "        for file_name, true_label, predicted_label, confidence in zip(all_file_names, all_labels, all_predictions,\n",
    "                                                                      confidences):\n",
    "            writer.writerow([file_name, true_label, predicted_label, confidence])\n",
    "    print(f\"予測結果が {OUTPUT_CSV} に保存されました。\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # メイン実行\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755efc1-6e67-45f5-af2e-446a8b98bc31",
   "metadata": {},
   "source": [
    "# カリキュラム学習\n",
    "#### カリキュラム学習とは\n",
    "学習データの難易度を徐々に増していくことにより，初期の簡単なデータで学習モデルの基盤を完成させ，後に難しいデータを学習させることにより，汎用性を向上させる，また難易度の高いデータに頑健なモデルを作成する学習方法．\n",
    "\n",
    "- 今回のカリキュラム学習では学習データの難易度を上記で学習したReSNetの出力するConfidence値とする\n",
    "- 訓練データを一度ReSNetモデルに入力し，Confidence値を算出する．その後，Confidence値の閾値によって訓練データを容易・困難の２種データセットにに分ける．\n",
    "- また，ResNetのモデルで高いConfidence値だが不正解だったサンプルも困難データセットに入れる\n",
    "\n",
    "- 簡単データローダーで４エポック，困難データローダーで８エポック学習する．（ここの学習エポック数は適正か不明．検討の余地あり）\n",
    "\n",
    "- カリキュラム学習に使用したモデル，初めと同じReSNetモデル．ただし，特徴量抽出層はImage-Netで学習した重み．全結合層は初期化する．（初期学習モデルの重みは使用しない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a689103-f5d1-4d83-83be-38eee206b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score  # 精度計算のために追加\n",
    "\n",
    "# シード値の設定\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# データの格納先ディレクトリとクラス名\n",
    "ORIGINAL_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/split_data\"\n",
    "AUGMENTED_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/augmented_data2\"\n",
    "CLASS_NAMES = [\"not-hold\", \"hold\"]\n",
    "MODEL_PATH = \"best_model_ResNet_aug.pth\"\n",
    "BEST_CURRICULUM_MODEL_PATH = \"best_curriculum_model_latest.pth\"\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# カスタムデータセットクラス\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, original_data_dir, augmented_data_dir=None, split='train', class_names=CLASS_NAMES,\n",
    "                 transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        # データセットの読み込み\n",
    "        for label, class_name in enumerate(class_names):\n",
    "            class_dir = os.path.join(original_data_dir, split, class_name)\n",
    "            image_paths = glob.glob(f\"{class_dir}/*.jpg\")\n",
    "            self.images.extend(image_paths)\n",
    "            self.labels.extend([label] * len(image_paths))\n",
    "\n",
    "            # 増強データが指定されている場合、増強データも追加\n",
    "            if augmented_data_dir and split == 'train':\n",
    "                augmented_class_dir = os.path.join(augmented_data_dir, class_name)\n",
    "                augmented_image_paths = glob.glob(f\"{augmented_class_dir}/*.jpg\")\n",
    "                self.images.extend(augmented_image_paths)\n",
    "                self.labels.extend([label] * len(augmented_image_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        file_name = os.path.basename(self.images[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, file_name\n",
    "\n",
    "# データローダーの準備\n",
    "def get_dataloader(split='train', batch_size=8):\n",
    "    if split == 'train':\n",
    "        dataset = MyDataset(ORIGINAL_DATA_DIR, AUGMENTED_DATA_DIR, split=split)\n",
    "    else:\n",
    "        dataset = MyDataset(ORIGINAL_DATA_DIR, split=split)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# カスタムデータローダーを作成する関数\n",
    "class SubsetDataset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        image, label, _ = self.dataset[data_idx]\n",
    "        return image, label\n",
    "\n",
    "def get_custom_dataloader(indices, dataset, batch_size=8):\n",
    "    subset = SubsetDataset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# モデルの評価\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    confidences = []\n",
    "    all_indices = []  # インデックスを収集\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target, file_name) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            conf, preds = torch.max(probs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            confidences.extend(conf.cpu().numpy())\n",
    "            # バッチ内のインデックスを取得\n",
    "            batch_start = batch_idx * loader.batch_size\n",
    "            batch_indices = [batch_start + i for i in range(len(data))]\n",
    "            all_indices.extend(batch_indices)\n",
    "    return all_labels, all_preds, confidences, all_indices\n",
    "\n",
    "# 検証損失を計算\n",
    "def calculate_val_loss(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target, _ in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# モデルの精度を計算\n",
    "def evaluate_model_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target, _ in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy\n",
    "\n",
    "# 難易度を取得し、簡単サンプルと難しいサンプルの数を均等にし、さらにクラスごとに均等にする\n",
    "def get_difficulty_data(all_labels, all_predictions, confidences, all_indices, dataset):\n",
    "    easy_samples = []\n",
    "    hard_samples = []\n",
    "\n",
    "    for idx, label, pred, conf in zip(all_indices, all_labels, all_predictions, confidences):\n",
    "        if label == pred and conf >= 0.99999:\n",
    "            easy_samples.append(idx)\n",
    "        else:\n",
    "            hard_samples.append(idx)\n",
    "\n",
    "    # 簡単サンプルと難しいサンプルの数を揃える前にシャッフル\n",
    "    print(f'Initial easy samples: {len(easy_samples)}, Initial hard samples: {len(hard_samples)}')\n",
    "    random.shuffle(easy_samples)\n",
    "\n",
    "    # 簡単サンプルの一部を難しいサンプルに移動し、数を同じにする\n",
    "    while len(easy_samples) > len(hard_samples):\n",
    "        hard_samples.append(easy_samples.pop())\n",
    "    print(f'Balanced easy samples: {len(easy_samples)}, Balanced hard samples: {len(hard_samples)}')\n",
    "\n",
    "    # クラスごとのサンプル数を均等にする関数\n",
    "    def balance_classes(indices):\n",
    "        class_0 = [idx for idx in indices if dataset.labels[idx] == 0]\n",
    "        class_1 = [idx for idx in indices if dataset.labels[idx] == 1]\n",
    "        min_class_samples = min(len(class_0), len(class_1))\n",
    "        return class_0[:min_class_samples] + class_1[:min_class_samples]\n",
    "\n",
    "    # クラスごとのサンプル数を均等にする\n",
    "    easy_samples = balance_classes(easy_samples)\n",
    "    hard_samples = balance_classes(hard_samples)\n",
    "\n",
    "    print(f'Adjusted easy samples: {len(easy_samples)}, Adjusted hard samples: {len(hard_samples)}')\n",
    "    return easy_samples, hard_samples\n",
    "\n",
    "# 学習関数\n",
    "def train(loader, epoch, model, criterion, optimizer, description=\"\"):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'{description} Epoch {epoch} | Batch {batch_idx} | Loss {loss.item():.6f}')\n",
    "\n",
    "# カリキュラム学習の関数\n",
    "def curriculum_learning(easy_indices, hard_indices, train_dataset):\n",
    "    # 検証用データローダー\n",
    "    val_loader = get_dataloader(split='val')\n",
    "\n",
    "    # 簡単サンプルと難しいサンプルからDataLoaderを作成\n",
    "    easy_loader = get_custom_dataloader(easy_indices, train_dataset)\n",
    "    hard_loader = get_custom_dataloader(hard_indices, train_dataset)\n",
    "\n",
    "    # モデルのセットアップ（ImageNetで事前学習された重みを使用）\n",
    "    model = resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, len(CLASS_NAMES))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    val_losses = []\n",
    "\n",
    "    # 簡単サンプルからの学習\n",
    "    print(\"Starting curriculum learning with easy samples\")\n",
    "    for epoch in range(4):\n",
    "        train(easy_loader, epoch, model, criterion, optimizer, description=\"Easy\")\n",
    "        val_loss = calculate_val_loss(model, val_loader, criterion)\n",
    "        val_accuracy = evaluate_model_accuracy(model, val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Validation Loss after Easy Epoch {epoch}: {val_loss:.6f}, Accuracy: {val_accuracy:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), BEST_CURRICULUM_MODEL_PATH)\n",
    "\n",
    "    # 難しいサンプルでの学習\n",
    "    print(\"Continuing curriculum learning with hard samples\")\n",
    "    for epoch in range(8):\n",
    "        train(hard_loader, epoch, model, criterion, optimizer, description=\"Hard\")\n",
    "        val_loss = calculate_val_loss(model, val_loader, criterion)\n",
    "        val_accuracy = evaluate_model_accuracy(model, val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Validation Loss after Hard Epoch {epoch}: {val_loss:.6f}, Accuracy: {val_accuracy:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), BEST_CURRICULUM_MODEL_PATH)\n",
    "\n",
    "    # 損失の推移をプロット\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Loss during Curriculum Learning\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # モデルの読み込み（あなたのデータセットで学習済みの重みを使用）\n",
    "    model = resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, len(CLASS_NAMES))\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))  # あなたのモデルの重みをロード\n",
    "    model = model.to(device)\n",
    "\n",
    "    # データセットの準備\n",
    "    train_dataset = MyDataset(ORIGINAL_DATA_DIR, AUGMENTED_DATA_DIR, split='train')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 初期モデルで難易度判定のための予測とインデックスを取得\n",
    "    all_labels, all_predictions, confidences, all_indices = evaluate_model(model, train_loader)\n",
    "\n",
    "    # 難易度に基づくデータ分割\n",
    "    easy_indices, hard_indices = get_difficulty_data(all_labels, all_predictions, confidences, all_indices, train_dataset)\n",
    "\n",
    "    # カリキュラム学習の実行（新しいモデルを使用）\n",
    "    curriculum_learning(easy_indices, hard_indices, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd58e0-96f9-4955-80bd-1e222e02404f",
   "metadata": {},
   "source": [
    "# ReSNetモデル or カリキュラムReSNetモデルをテストデータに適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2b2b8-74a6-4eaa-a1f8-1d63b8ccdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 学習済みモデルのパスとクラス名(MODEL_PATHを変更させて，使用モデル（ReSNet,or,curriculum ResNet）を選択)\n",
    "MODEL_PATH = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/best_curriculum_model_latest.pth\"\n",
    "CLASS_NAMES = [\"not-hold\", \"hold\"]\n",
    "TEST_DATA_DIR = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/test/test\"\n",
    "OUTPUT_CSV = \"test_predictions_with_confidence_curriculum_latest.csv\"\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# カスタムデータセットクラス\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_data_dir, transform=None):\n",
    "        self.images = glob.glob(f\"{test_data_dir}/*.jpg\")\n",
    "        self.transform = transform if transform else transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        file_name = os.path.basename(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, file_name\n",
    "\n",
    "# モデルの準備\n",
    "model = resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(2048, len(CLASS_NAMES))\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# データローダーの準備（リサイズは省略）\n",
    "test_dataset = TestDataset(TEST_DATA_DIR)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "# 予測とCSV出力\n",
    "with open(OUTPUT_CSV, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['file_name', 'Predicted_Label', 'Confidence'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, file_names in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)  # 各クラスの確信度を計算\n",
    "            confidences, predicted_labels = torch.max(probabilities, 1)  # 最大の確信度とラベル\n",
    "\n",
    "            for file_name, predicted_label, confidence in zip(file_names, predicted_labels.cpu().numpy(), confidences.cpu().numpy()):\n",
    "                writer.writerow([file_name, predicted_label, confidence])\n",
    "\n",
    "print(f\"予測結果が {OUTPUT_CSV} に保存されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1072dde-c325-4309-a613-ac2db854789f",
   "metadata": {},
   "source": [
    "# アンサンブル学習\n",
    "\n",
    "- ReSNetモデルをベースモデルとして，Confidenceの閾値を基にルールベースで，ReSNetのConfidence値が低いサンプルにはカリキュラムReSNetの結果を適用するようにした．\n",
    "（これをアンサンブル学習といっていいか不明．結果をアンサンブルしただけ）\n",
    "- 本当はスタッキング学習などをしたかったが，ReSNetモデルで既にF1-scoreが0.998程度であったため，不正解データが極端に少なかった．よってスタッキング学習のメタ学習が上手くいかないと考えたため，ルールベースのアンサンブル学習を採用した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187dbe8-037f-4cae-b3bd-9a0044812545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルパス\n",
    "resnet_csv_path = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/test/test_predictions_with_confidence.csv\"\n",
    "gcn_csv_path = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/test/test_predictions_with_confidence_curriculum_latest.csv\"\n",
    "failed_csv_path = \"C:/Users/sugie/PycharmProjects/Study/SIGNATE/test/failed_images.csv\" # GCNで予測できなかったファイルのリスト\n",
    "output_csv_path = \"amsumble_result_ResNet_curriculum_latest_0.98_0.95.csv\"\n",
    "gcn_selected_output_path = \"curriculum_selected_samples_latest_0.98_0.95.csv\"\n",
    "\n",
    "# 閾値の設定\n",
    "RESNET_CONFIDENCE_THRESHOLD = 0.98\n",
    "GCN_CONFIDENCE_THRESHOLD = 0.95\n",
    "\n",
    "# ResNetとGCNの結果を読み込む\n",
    "resnet_df = pd.read_csv(resnet_csv_path)\n",
    "gcn_df = pd.read_csv(gcn_csv_path)\n",
    "failed_df = pd.read_csv(failed_csv_path)  # GCNで予測に失敗した画像のリスト\n",
    "\n",
    "# GCNで予測できなかったファイル名のリスト\n",
    "failed_files = set(failed_df['file_name'].tolist())\n",
    "\n",
    "# 結果を統合\n",
    "final_predictions = []\n",
    "\n",
    "for _, resnet_row in resnet_df.iterrows():\n",
    "    file_name = resnet_row['file_name']\n",
    "    resnet_label = resnet_row['Predicted_Label']\n",
    "    resnet_confidence = resnet_row['Confidence']\n",
    "\n",
    "    # GCNの予測結果を取得\n",
    "    if file_name in failed_files:\n",
    "        # GCNで予測に失敗した場合はResNetのラベルを使用\n",
    "        final_label = resnet_label\n",
    "        chosen_model = \"ResNet\"\n",
    "    else:\n",
    "        # GCNの結果が存在する場合\n",
    "        gcn_row = gcn_df[gcn_df['file_name'] == file_name]\n",
    "        if gcn_row.empty:\n",
    "            print(f\"Warning: {file_name} is missing in GCN predictions but not in failed list.\")\n",
    "            final_label = resnet_label\n",
    "            chosen_model = \"ResNet\"\n",
    "        else:\n",
    "            gcn_label = gcn_row['Predicted_Label'].values[0]\n",
    "            gcn_confidence = gcn_row['Confidence'].values[0]\n",
    "\n",
    "            # フロー図に基づいた最終予測ラベルの決定\n",
    "            if resnet_confidence >= RESNET_CONFIDENCE_THRESHOLD:\n",
    "                final_label = resnet_label\n",
    "                chosen_model = \"ResNet\"\n",
    "            else:\n",
    "                if gcn_confidence >= GCN_CONFIDENCE_THRESHOLD:\n",
    "                    final_label = gcn_label\n",
    "                    chosen_model = \"GCN\"\n",
    "                else:\n",
    "                    final_label = resnet_label\n",
    "                    chosen_model = \"ResNet\"\n",
    "\n",
    "    # 最終結果をリストに追加\n",
    "    final_predictions.append({\n",
    "        \"file_name\": file_name,\n",
    "        \"ResNet_Label\": resnet_label,\n",
    "        \"ResNet_Confidence\": resnet_confidence,\n",
    "        \"GCN_Label\": gcn_label if not gcn_row.empty else None,\n",
    "        \"GCN_Confidence\": gcn_confidence if not gcn_row.empty else None,\n",
    "        \"Final_Predicted_Label\": final_label,\n",
    "        \"Chosen_Model\": chosen_model\n",
    "    })\n",
    "\n",
    "# データフレームに変換\n",
    "final_df = pd.DataFrame(final_predictions)\n",
    "\n",
    "# GCNが選択されたサンプルのみを抽出\n",
    "gcn_selected_df = final_df[final_df['Chosen_Model'] == \"GCN\"]\n",
    "\n",
    "# 最終結果をCSVに保存\n",
    "final_df.to_csv(output_csv_path, index=False)\n",
    "gcn_selected_df.to_csv(gcn_selected_output_path, index=False)\n",
    "\n",
    "print(f\"最終予測結果が {output_csv_path} に保存されました。\")\n",
    "print(f\"GCNが選択されたサンプルのみの結果が {gcn_selected_output_path} に保存されました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
